{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariate_storage_forecasting_with_Lag24.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAgQNbpgjZwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_B88MxtjgaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Oct 14 21:27:46 2018\n",
        "\n",
        "@author: 20584059\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,GRU\n",
        "from keras.layers import Dropout\n",
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "from keras import layers\n",
        "from functools import reduce\n",
        "#from phased_lstm_keras.PhasedLSTM import PhasedLSTM as PLSTM\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Activation\n",
        "from numpy import concatenate\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from pandas import ExcelWriter  \n",
        "def scale(a):\n",
        "\ta_min = np.nanmin(a, 0)\n",
        "\ta_max = np.nanmax(a, 0)\n",
        "\treturn (a - a_min) / (a_max - a_min), a_min, a_max\n",
        "\n",
        "\n",
        "def unscale(a_sc, amin, amax):\n",
        "\treturn a_sc * (amax - amin) + amin\n",
        "\n",
        "\n",
        "def factors(n):\n",
        "\treturn set(reduce(list.__add__,\n",
        "\t\t\t\t\t  ([i, n // i] for i in range(1, int(pow(n, 0.5) + 1)) if n % i == 0)))\n",
        "\n",
        "\n",
        "def NSE(y_observed, y_predicted):\n",
        "\tNSE_coefficient = 1 - sum((y_predicted[-2] - y_observed[:-2]) ** 2) / sum((y_observed - np.mean(y_observed)) ** 2)\n",
        "\treturn NSE_coefficient\n",
        "def MAPE(y_observed, y_predicted):\n",
        "\tMAPE_coefficient = np.mean((abs(y_observed-y_predicted)/y_observed))*100\n",
        "\treturn MAPE_coefficient\n",
        "def RMSE(y_observed, y_predicted):\n",
        "\tRMSE_coefficient = np.sqrt(np.mean((y_predicted - y_observed[:-1]) ** 2))\n",
        "\treturn RMSE_coefficient\n",
        "dataset = read_csv('/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Final_Lag24_storage_Data.csv', header=0,index_col=0)\n",
        "#dataset = dataset.drop(['Chd_Cereals(t) / PERCENTILE(Nig_Pigss)'],axis = 1)\n",
        "values = dataset.values\n",
        "#--- reading the dataset, splitting and defining the input/output data\n",
        "def data_preparation():\n",
        "    dataset = read_csv('/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Final_Lag24_storage_Data.csv', header=0,index_col=0)\n",
        "    #dataset = dataset.drop(['Chd_Cereals(t) / PERCENTILE(Nig_Pigss)'],axis = 1)\n",
        "    values = dataset.values\n",
        "    values = values.astype('float32')\n",
        "    scaled, value_min, value_max = scale(values)\n",
        "    n_hours_forecast = 1\n",
        "    n_hours = 1\n",
        "    n_features = 24\n",
        "    values = scaled\n",
        "    n_train_hours = 504\n",
        "    n_test_hours  = 564\n",
        "    val_test_hours= 600\n",
        "    train = values[:n_train_hours, :]\n",
        "    test  = values[n_train_hours :n_test_hours,:]\n",
        "    val   = values[n_test_hours: val_test_hours,:]\n",
        "    # split into input and outputs\n",
        "    n_obs = n_hours * n_features\n",
        "    return n_obs,train,test,val,value_min,value_max\n",
        "n_obs,train,test,val,value_min,value_max=data_preparation()\n",
        "n_hours_forecast = 1\n",
        "n_hours = 1\n",
        "n_features = 24\n",
        "steps_before = 1\n",
        "steps_after=1\n",
        "feature_count = n_features\n",
        "n_obs = n_hours * n_features\n",
        "# many(18*4) to many(6*4)\n",
        "train_X, train_y = train[:, :n_obs], train[:, n_obs:]\n",
        "print(train_X.shape,train_y.shape)\n",
        "test_X, test_y = test[:, :n_obs], test[:, n_obs:]\n",
        "print(test_X.shape,test_y.shape)\n",
        "val_X, val_y   = val[:, :n_obs], val[:, n_obs:]\n",
        "print(val_X.shape,val_y.shape)\n",
        "# need to reshape X arrays for use with LSTM\n",
        "train_X_reshaped = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "test_X_reshaped  = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "val_X_reshaped   = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
        "# need to reshape Y arrays for use with LSTM\n",
        "train_y_reshaped = train_y.reshape((train_y.shape[0], n_hours_forecast, n_hours_forecast))\n",
        "test_y_reshaped  = test_y.reshape((test_y.shape[0], n_hours_forecast, n_hours_forecast))\n",
        "val_y_reshaped   = val_y.reshape((val_y.shape[0], n_hours_forecast, n_hours_forecast))\n",
        "def baseline_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20, input_shape=(train_X_reshaped.shape[1], train_X_reshaped.shape[2]), return_sequences=False, activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    # model.add(LSTM(2, kernel_regularizer=L1L2(0.01, 0.01)))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    # Compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def features_prediction(n_obs,train,test):\n",
        "    #trainNSE_calc_list = []\n",
        "    trainMAPE_calc_list = []\n",
        "    trainRMSE_calc_list = []\n",
        "    #testNSE_calc_list = []\n",
        "    testMAPE_calc_list = []\n",
        "    testRMSE_calc_list = []\n",
        "    #valNSE_calc_list = []\n",
        "    valMAPE_calc_list = []\n",
        "    valRMSE_calc_list = []\n",
        "    train_y_unscaled_list = []\n",
        "    ytrain_predicted_unscaled_list= []\n",
        "    test_y_unscaled_list = []\n",
        "    ytest_predicted_unscaled_list = []\n",
        "    val_y_unscaled_list = []\n",
        "    yval_predicted_unscaled_list  = []\n",
        "    trainstd_calc_list = []\n",
        "    teststd_calc_list  = []\n",
        "    valstd_calc_list   = []\n",
        "#    trainResults = DataFrame()\n",
        "#    testResults  = DataFrame()\n",
        "#    valResults   = DataFrame()\n",
        "    for i in range(1):\n",
        "        train_X, train_y = train[:, :n_obs], train[:, i]\n",
        "        test_X, test_y = test[:, :n_obs], test[:, i]\n",
        "        val_X, val_y   = val[:, :n_obs], val[:, i]\n",
        "        train_X_reshaped = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "        test_X_reshaped = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "        val_X_reshaped   = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
        "        model = KerasRegressor(build_fn=baseline_model, epochs=20, batch_size=30, verbose=0)\n",
        "        #model.fit(train_X_reshaped,train_y,verbose=2)\n",
        "        \n",
        "        for j in range(30):\n",
        "            history = model.fit(train_X_reshaped, train_y, epochs=2000, batch_size=30, validation_data=(test_X_reshaped, test_y), verbose=1, shuffle=False)\n",
        "            pd.DataFrame(model.fit(train_X_reshaped, train_y, epochs=2000, batch_size=30, validation_data=(test_X_reshaped, test_y), verbose=1, shuffle=False).history).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/UVSTO_history\"+str(j)+\".csv\")\n",
        "            plt.plot(history.history['loss'], label='CLUGR train set')\n",
        "            plt.plot(history.history['val_loss'], label='CLUGR test set')\n",
        "            plt.legend()\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            #Predict on the trainset\n",
        "            ytrain_predicted = model.predict(train_X_reshaped)\n",
        "            ytrain_predicted_unscaled = unscale(ytrain_predicted,value_min[0],value_max[0])\n",
        "            ytrain_predicted_unscaled_list.append(ytrain_predicted_unscaled)\n",
        "            train_y_unscaled = unscale(train_y, value_min[0], value_max[0])\n",
        "            train_y_unscaled_list.append(train_y_unscaled)\n",
        "            forecast32 = ytrain_predicted_unscaled.reshape(-1,1)\n",
        "            forecast32 = pd.DataFrame(forecast32)\n",
        "            forecast32.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TrainsetCSVs/24Lags/trainsetcsv\"+str(j)+\".csv\")\n",
        "            #Predict on the testset\n",
        "            ytest_predicted = model.predict(test_X_reshaped)\n",
        "            ytest_predicted_unscaled = unscale(ytest_predicted,value_min[0],value_max[0])\n",
        "            ytest_predicted_unscaled_list.append(ytest_predicted_unscaled)\n",
        "            test_y_unscaled = unscale(test_y, value_min[0], value_max[0])\n",
        "            test_y_unscaled_list.append(test_y_unscaled)\n",
        "            forecast321 = ytest_predicted_unscaled.reshape(-1,1)\n",
        "            #forecast321 = test_y_unscaled_list\n",
        "            forecast321 = pd.DataFrame(forecast321)\n",
        "            forecast321.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TestsetCSVs/24Lags/testsetcsv\"+str(j)+\".csv\")\n",
        "            #Predict on the valset\n",
        "            yval_predicted = model.predict(val_X_reshaped)\n",
        "            yval_predicted_unscaled = unscale(yval_predicted,value_min[0],value_max[0])\n",
        "            yval_predicted_unscaled_list.append(yval_predicted_unscaled)\n",
        "            val_y_unscaled = unscale(val_y, value_min[0], value_max[0])\n",
        "            val_y_unscaled_list.append(val_y_unscaled)\n",
        "            forecast322 = yval_predicted_unscaled.reshape(-1,1)\n",
        "            #forecast322 = val_y_unscaled_list\n",
        "            forecast322 = pd.DataFrame(forecast322)\n",
        "            forecast322.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/ValsetCSVs/24Lags/valsetcsv\"+str(j)+\".csv\")\n",
        "            m =[]\n",
        "            m1=[]\n",
        "            m2=[]\n",
        "            m3=[]\n",
        "            m4=[]\n",
        "            m5=[]\n",
        "            stdpredtrain = []\n",
        "            stdpredtest  = []\n",
        "            stdvalpred   = []\n",
        "            valy = np.asarray(val_y_unscaled_list)\n",
        "            valy = valy.reshape(-1,1)\n",
        "            q=np.asarray(train_y_unscaled_list).reshape(-1,1)\n",
        "            k=np.asarray(test_y_unscaled_list).reshape(-1,1) \n",
        "            trainy=q.reshape(-1,1)\n",
        "            testy=k.reshape(-1,1)\n",
        "            for i in range(len(q)):\n",
        "              if trainy[i]>0 or trainy[i]<0:\n",
        "                a  = (np.asarray(train_y_unscaled_list).reshape(-1,1)[i]-np.asarray(ytrain_predicted_unscaled_list).reshape(-1,1)[i])**2\n",
        "                a1 = abs((np.asarray(train_y_unscaled_list).reshape(-1,1)[i]-np.asarray(ytrain_predicted_unscaled_list).reshape(-1,1)[i])/np.asarray(train_y_unscaled_list).reshape(-1,1)[i])\n",
        "                b1 = (np.asarray(ytrain_predicted_unscaled_list).reshape(-1,1)[i]-np.mean(np.asarray(ytrain_predicted_unscaled_list).reshape(-1,1)))**2\n",
        "                m.append(a)\n",
        "                m1.append(a1)\n",
        "                stdpredtrain.append(b1)\n",
        "            for i in range(len(k)):\n",
        "              if testy[i]>0 or testy[i]<0:\n",
        "                a2 = ((np.asarray(test_y_unscaled_list)).reshape(-1,1)[i]-(np.asarray(ytest_predicted_unscaled_list)).reshape(-1,1)[i])**2\n",
        "                a3 = abs(((np.asarray(test_y_unscaled_list)).reshape(-1,1)[i]-(np.asarray(ytest_predicted_unscaled_list)).reshape(-1,1)[i])/(np.asarray(test_y_unscaled_list)).reshape(-1,1)[i])\n",
        "                b2 = (np.asarray(ytest_predicted_unscaled_list).reshape(-1,1)[i]-np.mean(np.asarray(ytest_predicted_unscaled_list).reshape(-1,1)))**2\n",
        "                m2.append(a2)\n",
        "                m3.append(a3)\n",
        "                stdpredtest.append(b2)\n",
        "                tg = np.asarray(yval_predicted_unscaled_list).reshape(-1,1)\n",
        "            for i in range(len(tg)):\n",
        "                if valy[i]>0 or valy[i]<0:\n",
        "                    a4 = (np.asarray(val_y_unscaled_list).reshape(-1,1)[i]-np.asarray(np.asarray(yval_predicted_unscaled_list)).reshape(-1,1)[i])**2\n",
        "                    b3 = ((np.asarray(yval_predicted_unscaled_list)).reshape(-1,1)[i]-np.mean(np.asarray(yval_predicted_unscaled_list)).reshape(-1,1))**2\n",
        "                    a5 = abs((np.asarray(val_y_unscaled_list).reshape(-1,1)[i]-np.asarray(yval_predicted_unscaled_list).reshape(-1,1)[i])/np.asarray(val_y_unscaled_list).reshape(-1,1)[i])\n",
        "                    m4.append(a4)\n",
        "                    m5.append(a5)\n",
        "                    stdvalpred.append(b3)\n",
        "                C1=np.sqrt(np.mean(m))\n",
        "                V1=np.mean(m1)*100\n",
        "                C2=np.sqrt(np.mean(m2))\n",
        "                V2=np.mean(m3)*100\n",
        "                C3=np.sqrt(np.mean(m4))\n",
        "                V3=np.mean(m5)*100\n",
        "                B1=np.sqrt(np.mean(stdpredtrain))\n",
        "                B2=np.sqrt(np.mean(stdpredtest))\n",
        "                B3=np.sqrt(np.mean(stdvalpred))\n",
        "                \n",
        "            #print('TS_RMSE:',C1,'TS_MAPE:',V1,'CS_RMSE:',C2,'CS_MAPE:',V2,'Test_RMSE:',C3,'Test_MAPE:',V3)            \n",
        "            #trainNSE_calc = NSE(train_y_unscaled,ytrain_predicted_unscaled)\n",
        "            #trainRMSE_calc = RMSE(train_y_unscaled,ytrain_predicted_unscaled)\n",
        "            #trainMAPE_calc = MAPE(train_y_unscaled,ytrain_predicted_unscaled)\n",
        "            #trainNSE_calc_list.append(trainNSE_calc)\n",
        "            trainRMSE_calc_list.append(C1)\n",
        "            trainMAPE_calc_list.append(V1)\n",
        "            trainstd_calc_list.append(B1)\n",
        "            #testNSE_calc = NSE(test_y_unscaled,ytest_predicted_unscaled)\n",
        "            #testRMSE_calc = RMSE(test_y_unscaled,ytest_predicted_unscaled)\n",
        "            #testMAPE_calc = MAPE(test_y_unscaled,ytest_predicted_unscaled)\n",
        "            #testNSE_calc_list.append(testNSE_calc)\n",
        "            testRMSE_calc_list.append(C2)\n",
        "            testMAPE_calc_list.append(V2)\n",
        "            teststd_calc_list.append(B2)\n",
        "            #valNSE_calc = NSE(val_y_unscaled,yval_predicted_unscaled)\n",
        "            #valRMSE_calc = RMSE(val_y_unscaled,yval_predicted_unscaled)\n",
        "            #valMAPE_calc = MAPE(val_y_unscaled,yval_predicted_unscaled)\n",
        "            #valNSE_calc_list.append(valNSE_calc)\n",
        "            valRMSE_calc_list.append(C3)\n",
        "            valMAPE_calc_list.append(V3)\n",
        "            valstd_calc_list.append(B3)\n",
        "        return trainstd_calc_list,teststd_calc_list,valstd_calc_list, trainRMSE_calc_list,trainMAPE_calc_list,testRMSE_calc_list,testMAPE_calc_list,valRMSE_calc_list,valMAPE_calc_list,train_y_unscaled_list,ytrain_predicted_unscaled_list,test_y_unscaled_list,ytest_predicted_unscaled_list,val_y_unscaled_list,yval_predicted_unscaled_list\n",
        "\n",
        "\n",
        "trainstd_calc_list,teststd_calc_list,valstd_calc_list,trainRMSE_calc_list,trainMAPE_calc_list,testRMSE_calc_list,testMAPE_calc_list,valRMSE_calc_list,valMAPE_calc_list,train_y_unscaled_list,ytrain_predicted_unscaled_list,test_y_unscaled_list,ytest_predicted_unscaled_list,val_y_unscaled_list,yval_predicted_unscaled_list = features_prediction(n_obs,train,test)\n",
        "\n",
        "#Save performances in the drive\n",
        "pd.DataFrame(trainstd_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/stdtrainset.csv\")\n",
        "pd.DataFrame(teststd_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/stdtestset.csv\")\n",
        "pd.DataFrame(valstd_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/stdvalset.csv\")\n",
        "pd.DataFrame(trainRMSE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsetrainset.csv\")\n",
        "pd.DataFrame(trainMAPE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapetrainset.csv\")\n",
        "pd.DataFrame(testRMSE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsetestset.csv\")\n",
        "pd.DataFrame(testMAPE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapetestset.csv\")\n",
        "pd.DataFrame(valRMSE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsevalset.csv\")\n",
        "pd.DataFrame(valMAPE_calc_list).to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapevalset.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irIegzRExEJw",
        "colab_type": "text"
      },
      "source": [
        "##SAVE THE RMSE AND MAPE IN CSV FILE AND COMPUTE AVERAGE PERFORMANCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVNR8Iz_kAjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df  = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsetrainset.csv\",index_col=0,header = 0)\n",
        "dfm = pd.DataFrame(df).mean()\n",
        "dfs = pd.DataFrame(df).std()\n",
        "s1  = pd.DataFrame(dfm).rename({'0':'trainset_mrmse'})\n",
        "s2  = pd.DataFrame(dfs).rename({'0':'trainset_stdmrmse'})\n",
        "RFreport = pd.concat([s1,s2],axis=1,ignore_index=False)\n",
        "df1 = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapetrainset.csv\",index_col=0,header = 0)\n",
        "dfm1= pd.DataFrame(df1).mean()\n",
        "dfs1= pd.DataFrame(df1).std()\n",
        "s11 = pd.DataFrame(dfm1).rename({'0':'trainset_mape'})\n",
        "s21 = pd.DataFrame(dfs1).rename({'0':'trainset_stdmape'})\n",
        "RFreport = pd.concat([RFreport,s11,s21],axis=1,ignore_index=False)\n",
        "df2  = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsetestset.csv\",index_col=0,header = 0)\n",
        "dfm2 = pd.DataFrame(df2).mean()\n",
        "dfs2 = pd.DataFrame(df2).std()\n",
        "s12  = pd.DataFrame(dfm2).rename({'0':'testset_mrmse'})\n",
        "s22  = pd.DataFrame(dfs2).rename({'0':'testset_stdmrmse'})\n",
        "RFreport = pd.concat([RFreport,s12,s22],axis=1,ignore_index=False)\n",
        "df3  = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapetestset.csv\",index_col=0,header = 0)\n",
        "dfm3 = pd.DataFrame(df3).mean()\n",
        "dfs3 = pd.DataFrame(df3).std()\n",
        "s13  = pd.DataFrame(dfm3).rename({'0':'testset_mape'})\n",
        "s23  = pd.DataFrame(dfs3).rename({'0':'testset_stdmape'})\n",
        "RFreport = pd.concat([RFreport,s13,s23],axis=1,ignore_index=False)\n",
        "df4  = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/rmsevalset.csv\",index_col=0,header = 0)\n",
        "dfm4 = pd.DataFrame(df4).mean()\n",
        "dfs4 = pd.DataFrame(df4).std()\n",
        "s14  = pd.DataFrame(dfm4).rename({'0':'valset_rmse'})\n",
        "s24  = pd.DataFrame(dfs4).rename({'0':'valset_stdrmse'})\n",
        "RFreport = pd.concat([RFreport,s14,s24],axis=1,ignore_index=False)\n",
        "df5  = pd.read_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/mapevalset.csv\",index_col=0,header = 0)\n",
        "dfm5 = pd.DataFrame(df5).mean()\n",
        "dfs5 = pd.DataFrame(df5).std()\n",
        "s15  = pd.DataFrame(dfm5).rename({'0':'valset_mape'})\n",
        "s25  = pd.DataFrame(dfs5).rename({'0':'valset_stdmape'})\n",
        "RFreport = pd.concat([RFreport,s15,s25],axis=1,ignore_index=False)\n",
        "RFreport = RFreport.transpose()\n",
        "RFreport = pd.DataFrame(RFreport.sum(axis=0))\n",
        "\n",
        "RFreport.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Performances/24Lags/Lag24_Sto_performancereport.csv\")                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFPWd9OGxfxO",
        "colab_type": "text"
      },
      "source": [
        "##CONCATENATE RESULTS OBTAINED FROM 30 SIMULATIONS IN ONE CSV FILE AND COMPUTE AVERAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzIQuStjkCGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Concatenate the csvfiles and compute the mean\n",
        "import pandas as pd\n",
        "import glob\n",
        "#Concatenate train, val and testsets and compute the mean values that are used as final output\n",
        "\n",
        "path = r'./gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TrainsetCSVs/24Lags' # use your path\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=0, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=1, ignore_index=False)\n",
        "frame1 = frame.mean(axis = 1) \n",
        "frame.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TrainsetCSVs/24Lags/concat_predictions.csv\")\n",
        "frame1.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TrainsetCSVs/24Lags/mean_predictions.csv\")\n",
        "\n",
        "path = r'./gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TestsetCSVs/24Lags' # use your path\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=0, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=1, ignore_index=False)\n",
        "frame1 = frame.mean(axis = 1) \n",
        "frame.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TestsetCSVs/24Lags/concat_predictions.csv\")\n",
        "frame1.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/TestsetCSVs/24Lags/mean_predictions.csv\")\n",
        "\n",
        "path = r'./gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/ValsetCSVs/24Lags' # use your path\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=0, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=1, ignore_index=False)\n",
        "#rame1 = frame.mean(axis = 1) \n",
        "frame.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/ValsetCSVs/24Lags/concat_predictions.csv\")\n",
        "frame1.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/Model_for_WDDE/SCM/LULSGR_Forecasting/Nigeria/Livestocks_GRF/Sheep/Results/ValsetCSVs/24Lags/mean_predictions.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFQ2NZNTx5Ue",
        "colab_type": "text"
      },
      "source": [
        "##CONCATENATE LOSS HISTORY IN ONE CSV AND COMPUTE AVERAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UGs8GjUkN1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "path = r'./content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags' # use your path\n",
        "for j in range(30):\n",
        "  all_files = glob.glob(path + \"/Lag24_history\"+str(j)+\".csv\")\n",
        "\n",
        "li = []\n",
        "li1 = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=0, header=0)\n",
        "    df1 = df['loss']\n",
        "    df2 = df['val_loss']\n",
        "    li.append(df1)\n",
        "    li1.append(df2)\n",
        "\n",
        "frame1 = pd.concat(li, axis=1, ignore_index=False)\n",
        "frame2 = pd.concat(li1, axis=1, ignore_index=False)\n",
        "frame3 = frame1.mean(axis = 1) \n",
        "frame4 = frame2.mean(axis = 1)\n",
        "frame1.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/concat_loss_function.csv\")\n",
        "frame2.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/concat_val_loss_function.csv\")\n",
        "frame3.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/mean_loss_function.csv\")\n",
        "frame4.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/mean_val_loss_function.csv\")\n",
        "loss = pd.concat([frame3,frame4],axis = 1,ignore_index=False)\n",
        "loss.to_csv(\"/content/gdrive/My Drive/PHD_THESIS/PAPER1/STORAGE_FORECAST/UVLSTM/Results/Loss_history/24Lags/mean_loss_val_loss_functions.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}